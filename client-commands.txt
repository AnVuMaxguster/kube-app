# Install awscli, kubectl, kops
# Configure awscli with access credentials 

# Create S3 bucket ( for storing cluster state  )
aws s3api create-bucket \
  --bucket connor-kop-states \
  --region us-east-1

# Create EBS volume ( for mounting it to the database )
# It has to be in the same zone with the node running database pod
aws ec2 create-volume \
  --availability-zone us-east-1b \
  --size 3 \
  --volume-type gp2

# Bring up cluster: create - update

# Bring down cluster ( & remove ): delete

kops create cluster --name=kubevpro \ 
--state=s3://connor-kop-states --zones=us-east-1a,us-east-1b \ 
--node-count=2 --node-size=t3.small --master-size=t3.medium --dns-zone=kubevpro.maxguster.id.vn \ 
--node-volume-size=8 --master-volume-size=8

kops update cluster --name kubevpro --state=s3://connor-kop-states --yes --admin

kops delete cluster --name kubevpro --state=s3://connor-kop-states --yes --admin

# Note: S3 buckets, EC2 instances, EBS volumes used for the cluster have to be in the same region